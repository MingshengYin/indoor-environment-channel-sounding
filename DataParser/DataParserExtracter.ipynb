{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import os\n",
    "import collections\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import shutil\n",
    "from numpy import loadtxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ParsingError(Exception):\n",
    "    pass\n",
    "\n",
    "class P2mPaths:\n",
    "    \"\"\"Parse a p2m paths file\"\"\"\n",
    "\n",
    "    # project.type.tx_y.rz.p2m\n",
    "    _filename_match_re = (r'^(?P<project>.*)' +\n",
    "                          r'\\.' +\n",
    "                          r'(?P<type>((doa)|(paths)|(cir)))' +\n",
    "                          r'\\.' +\n",
    "                          r't(?P<transmitter>\\d+)'+\n",
    "                          r'_' +\n",
    "                          r'(?P<transmitter_set>\\d+)' +\n",
    "                          r'\\.' +\n",
    "                          r'r(?P<receiver_set>\\d+)' +\n",
    "                          r'\\.' +\n",
    "                          r'p2m$')\n",
    "\n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.file = None\n",
    "        self._parse()\n",
    "\n",
    "    def get_data_dict(self):\n",
    "        return self.cvs_data\n",
    "    \n",
    "    def get_num_receiver(self):\n",
    "        return self.n_receivers\n",
    "\n",
    "    def _parse(self):\n",
    "        with open(self.filename) as self.file:\n",
    "            self._parse_meta()\n",
    "            self._parse_header()\n",
    "#             self.data = collections.OrderedDict()\n",
    "            self.cvs_data = collections.OrderedDict()\n",
    "            for rec in range(self.n_receivers):\n",
    "                self._parse_receiver()\n",
    "\n",
    "    def _parse_meta(self):\n",
    "        match = re.match(P2mPaths._filename_match_re,\n",
    "                         os.path.basename(self.filename))\n",
    "\n",
    "        self.project = match.group('project')\n",
    "        self.transmitter_set = int(match.group('transmitter_set'))\n",
    "        self.transmitter = int(match.group('transmitter'))\n",
    "        self.receiver_set = int(match.group('receiver_set'))\n",
    "\n",
    "    def _parse_header(self):\n",
    "        \"\"\"read the first line of the file, indicating the number of receivers\"\"\"\n",
    "        line = self._get_next_line()\n",
    "        self.n_receivers = int(line.strip())\n",
    "\n",
    "    def _get_next_line(self):\n",
    "        \"\"\"Get the next uncommedted line of the file\n",
    "\n",
    "        Call this only if a new line is expected\n",
    "        \"\"\"\n",
    "        if self.file is None:\n",
    "            raise ParsingError('File is closed')\n",
    "        while True:\n",
    "            next_line = self.file.readline()\n",
    "            if next_line == '':\n",
    "                raise ParsingError('Unexpected end of file')\n",
    "            if re.search(r'^\\s*#', next_line, re.DOTALL):\n",
    "                continue\n",
    "            else:\n",
    "                return next_line\n",
    "\n",
    "    def _parse_receiver(self):\n",
    "        \"\"\"Get receiver and number of paths (pair Tx-Rx)\"\"\"\n",
    "        line = self._get_next_line()\n",
    "        receiver, n_paths = [int(i) for i in line.split()]\n",
    "        self.cvs_data[receiver] = collections.OrderedDict()\n",
    "        if n_paths == 0:\n",
    "\n",
    "            self.cvs_data[receiver] = None\n",
    "            return\n",
    "        \"\"\"Read: received_power -self.data[receiver][0]-, arrival_time -self.data[receiver][1]-,\n",
    "         spread_delay -self.data[receiver][2]-\"\"\"\n",
    "        #These are statistics per receiver (accounts for all paths)\n",
    "        line = self._get_next_line()\n",
    "        received_power, arrival_time, spread_delay = [float(i) for i in line.split()]\n",
    "\n",
    "        \n",
    "        self.cvs_data[receiver]['total_received_power'] = received_power\n",
    "        self.cvs_data[receiver]['mean_arrival_time'] = arrival_time\n",
    "        self.cvs_data[receiver]['spread_delay'] = spread_delay\n",
    "        self.cvs_data[receiver]['paths_number'] = n_paths\n",
    "        \n",
    "        \"\"\"Read for version 3.2: srcvdpower, arrival_time, arrival_angle1, arrival_angle2, departure_angle1, departure_angle2\"\"\"\n",
    "        \"\"\"or read for version 3.3: srcvdpower, phase, arrival_time, arrival_angle1, arrival_angle2, departure_angle1, departure_angle2\"\"\"\n",
    "        #now get statistics per path\n",
    "        for rays in range(0,n_paths):\n",
    "            line = self._get_next_line()\n",
    "            line_values_as_list = line.split() #split line and organize values as list\n",
    "            if len(line_values_as_list) == 8: #version 3.2\n",
    "                ray_n, n_interactions, srcvdpower, arrival_time, arrival_angle1, arrival_angle2, departure_angle1, departure_angle2 = [float(i) for i in line.split()]\n",
    "            elif len(line_values_as_list) == 9: #version 3.3\n",
    "                ray_n, n_interactions, srcvdpower, phase, arrival_time, arrival_angle1, arrival_angle2, departure_angle1, departure_angle2  = [float(i) for i in line.split()]\n",
    "            else:\n",
    "                raise Exception(line + ' has ' + len(line_values_as_list) + ' but was expecting 8 or 9!')\n",
    "            interactions_list = self._get_next_line().strip()\n",
    "            ray_n = int(ray_n)\n",
    "            n_interactions = int(n_interactions)\n",
    "            \n",
    "            self.cvs_data[receiver][str(rays+1)+'_srcvdpower'] = srcvdpower\n",
    "            \n",
    "            if len(line_values_as_list) == 9: #version 3.3\n",
    "            \n",
    "                self.cvs_data[receiver][str(rays+1)+'_phase'] = phase\n",
    "            self.cvs_data[receiver][str(rays+1)+'_arrival_time'] = arrival_time\n",
    "            self.cvs_data[receiver][str(rays+1)+'_arrival_angle1'] = arrival_angle1\n",
    "            self.cvs_data[receiver][str(rays+1)+'_arrival_angle2'] = arrival_angle2\n",
    "            self.cvs_data[receiver][str(rays+1)+'_departure_angle1'] = departure_angle1\n",
    "            self.cvs_data[receiver][str(rays+1)+'_departure_angle2'] = departure_angle2\n",
    "            self.cvs_data[receiver][str(rays+1)+'_interactions_list'] = interactions_list\n",
    "            self.cvs_data[receiver][str(rays+1)+'_interactions'] = collections.OrderedDict()\n",
    "            self.cvs_data[receiver][str(rays+1)+'_n_interactions'] = n_interactions #store integer\n",
    "            \n",
    "            \"\"\"Get coordinates of interactions\"\"\"\n",
    "            for i in range(n_interactions+2): #add 2 to take in account Tx and Rx\n",
    "                \n",
    "                line = self._get_next_line()\n",
    "                sp_line = line.split()\n",
    "                interaction = i \n",
    "                coordinates = np.array([float(j) for j in sp_line[0:]])\n",
    "              \n",
    "                self.cvs_data[receiver][str(rays+1)+'_interactions'][str(interaction)] = coordinates\n",
    "                if rays == 0 and i == 0 :\n",
    "                    Tx_coordinates = coordinates\n",
    "                    self.cvs_data[receiver]['Tx_coordinates'] = Tx_coordinates\n",
    "                if rays == 0 and i == n_interactions+1:\n",
    "                    Rx_coordinates = coordinates\n",
    "                    self.cvs_data[receiver]['Rx_coordinates'] = Rx_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cvsGen(projectDirectory, projectName):\n",
    "    \n",
    "    cvsPath = ['.\\\\cvsResults\\\\' + name for name in projectName]\n",
    "    for i in range(len(cvsPath)):\n",
    "        os.makedirs(cvsPath[i])\n",
    "    \n",
    "    for j in range(len(projectDirectory)):\n",
    "        directory = projectDirectory[j]\n",
    "        resultPath = cvsPath[j]\n",
    "        for file in os.listdir(directory):\n",
    "            if file.endswith(\".p2m\"):\n",
    "                if fnmatch.fnmatch(file,'*paths*'):\n",
    "                    print('Processing File: ',file)\n",
    "                    path = os.path.join(directory,file)\n",
    "                    p2mpath = P2mPaths(path)\n",
    "                    pd.DataFrame(pd.DataFrame.from_dict(p2mpath.get_data_dict()).transpose()).to_csv(os.path.join(resultPath,p2mpath.project+\"_Tx_\"+str(p2mpath.transmitter_set)+\".csv\"))\n",
    "            \n",
    "        tx_loc = []\n",
    "        # rx_loc = []\n",
    "        prev_tx = []\n",
    "\n",
    "        # Check files in the specified directory\n",
    "        for file in os.listdir(directory):\n",
    "        # Process only p2m files\n",
    "            if file.endswith(\".p2m\"):\n",
    "\n",
    "                # Use path files for the TX locations\n",
    "                if fnmatch.fnmatch(file,'*paths*'):\n",
    "\n",
    "                    # Open file\n",
    "                    path = os.path.join(directory,file)\n",
    "                    with open(path) as openfileobject:\n",
    "                        for line in openfileobject:\n",
    "                            # Look for a any scattering interaction\n",
    "                            # Note this may not work if the TX is in outage with every single RX\n",
    "                            if fnmatch.fnmatch(line,'Tx-*'):\n",
    "                                # Collect and process the TX location \n",
    "                                # (First entry in the interaction list)\n",
    "                                curr_line = openfileobject.readline()\n",
    "                                arr_line = curr_line.split()\n",
    "\n",
    "                                new_tx = [arr_line[0], arr_line[1], arr_line[2]]\n",
    "\n",
    "                                # Append only if this is an unrecorded TX location\n",
    "                                if new_tx != prev_tx:\n",
    "                                    tx_loc.append([arr_line[0], arr_line[1], arr_line[2]])\n",
    "                                    prev_tx = new_tx\n",
    "\n",
    "                            else:\n",
    "                                continue\n",
    "\n",
    "                # Use txloss files for the RX locations                 \n",
    "                # elif fnmatch.fnmatch(file,'*txloss.t001*'):\n",
    "\n",
    "                #     # Open file\n",
    "                #     path = os.path.join(directory,file)\n",
    "                #     with open(path) as openfileobject:\n",
    "                #         for line in openfileobject:\n",
    "                #             # Ignore header\n",
    "                #             if re.search(r'^\\s*#', line, re.DOTALL):\n",
    "                #                 continue\n",
    "\n",
    "                #             # The first non-header line contains the RX coordinates\n",
    "                #             arr_line = line.split()\n",
    "\n",
    "                #             # Append the new RX location\n",
    "                #             rx_loc.append([arr_line[1], arr_line[2], arr_line[3]])\n",
    "\n",
    "        # Convert to data frame            \n",
    "        df_tx = pd.DataFrame(data = tx_loc,columns = ['x','y','z'])   \n",
    "        # df_rx = pd.DataFrame(data = rx_loc,columns = ['x','y','z'])\n",
    "\n",
    "        print('Exporting Tx pos')\n",
    "\n",
    "        # Export as CSV\n",
    "        output_tx = os.path.join(resultPath,'tx_pos.csv')\n",
    "        # output_rx = os.path.join(directory,'rx_pos.csv')\n",
    "\n",
    "        df_tx.to_csv(output_tx)   \n",
    "        # df_rx.to_csv(output_rx) \n",
    "        print('Done')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reach_value_array(keywords, npath, lineIndex, csv_data):\n",
    "    \n",
    "    names = []\n",
    "    for i in range(npath):\n",
    "        item = str(i+1)+keywords\n",
    "        names.append(item)\n",
    "    \n",
    "    data_object = csv_data.loc[lineIndex[0], names]\n",
    "    nparr = np.array(data_object).T\n",
    "    \n",
    "    for ind in lineIndex[1:]:\n",
    "        data_object = csv_data.loc[ind, names]\n",
    "        nparr0 = np.array(data_object).T\n",
    "        nparr = np.vstack((nparr, nparr0))\n",
    "    \n",
    "    nparr_doule = nparr.astype(np.float64)\n",
    "    return nparr_doule\n",
    "\n",
    "def extractData(file_name, project_name, result_path, npath, lineIndex):\n",
    "    \n",
    "    csv_data = pd.read_csv(file_name+'.csv')\n",
    "    srcvdpower = reach_value_array('_srcvdpower',npath, lineIndex, csv_data)\n",
    "    srcvdpower = reach_value_array('_srcvdpower',npath, lineIndex, csv_data)\n",
    "    arrival_time = reach_value_array('_arrival_time',npath, lineIndex, csv_data)\n",
    "    arrival_angle1 = reach_value_array('_arrival_angle1',npath, lineIndex, csv_data)\n",
    "    arrival_angle2 = reach_value_array('_arrival_angle2',npath, lineIndex, csv_data)\n",
    "    departure_angle1 = reach_value_array('_departure_angle1',npath, lineIndex, csv_data)\n",
    "    departure_angle2 = reach_value_array('_departure_angle2',npath, lineIndex, csv_data)   \n",
    "\n",
    "    sio.savemat(result_path+'_data.mat', {'gain': srcvdpower, 'dly': arrival_time, 'aoaEl': arrival_angle1, \n",
    "                                'aoaAz':arrival_angle2, 'aodEl': departure_angle1, 'aodAz':departure_angle2})\n",
    "    \n",
    "# generate the mat files from cvs\n",
    "def matGen(projectName):\n",
    "    matPath = ['.\\\\matResults\\\\' + name for name in projectName]\n",
    "    for i in range(len(matPath)):\n",
    "        if os.path.exists(matPath[i]):\n",
    "            shutil.rmtree(matPath[i])\n",
    "        os.makedirs(matPath[i])\n",
    "    \n",
    "    npath = 25\n",
    "    for j in range(len(projectName)):\n",
    "        \n",
    "        pjName = projectName[j]\n",
    "        print(\"Start: \" + pjName)\n",
    "        \n",
    "        topdownmap = loadtxt('.\\\\topDownMap\\\\'+\n",
    "                         pjName + '.glb_topdownmap.out', delimiter=\",\", unpack=False)\n",
    "        nx = topdownmap.shape[0]\n",
    "        ny = topdownmap.shape[1]\n",
    "        csv_data = pd.read_csv('.\\\\cvsResults\\\\' + pjName + '\\\\' + pjName + '_Tx_1' +'.csv')\n",
    "        ntx = csv_data.shape[0]\n",
    "        # zoom in map 3 times\n",
    "        xIndex = np.arange(1, nx, 3)\n",
    "        yIndex = np.arange(1, ny, 3)\n",
    "        zoomMap = topdownmap[xIndex,:]\n",
    "        zoomMap = zoomMap[:,yIndex]\n",
    "        roomIndex = []\n",
    "        for i in range(160):\n",
    "            for j in range(160):\n",
    "                if zoomMap[i][j] == 1 or zoomMap[i][j] == 2:\n",
    "                    roomIndex.append([i,j])\n",
    "        # convert index to line\n",
    "        roomIndex = np.array(roomIndex)\n",
    "        lineIndex = (159-roomIndex[:,0])*160 + roomIndex[:,1] # nparray\n",
    "        roomIndex_doule = roomIndex.astype(np.float64)\n",
    "        sio.savemat('.\\\\matResults\\\\' + pjName + '\\\\'\n",
    "                    + pjName +'_roomIndex.mat', {'roomIndex': roomIndex})\n",
    "        \n",
    "        for n in range(10):\n",
    "            fileName = '.\\\\cvsResults\\\\' + pjName + '\\\\' + pjName + '_Tx_' + str(n+1)\n",
    "            resultPath = '.\\\\matResults\\\\' + pjName + '\\\\' + pjName + '_Tx_' + str(n+1)\n",
    "            extractData(fileName,pjName,resultPath,npath,lineIndex)\n",
    "    print('Done') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Adrian\\n', 'Bowlus\\n', 'Brevort\\n', 'Capistrano\\n']\n",
      "Working on: \n",
      "Bowlus2\n",
      "Processing File:  Bowlus2.paths.t001_01.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_02.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_03.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_04.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_05.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_06.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_07.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_08.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_09.r011.p2m\n",
      "Processing File:  Bowlus2.paths.t001_10.r011.p2m\n",
      "Exporting Tx pos\n",
      "Done\n",
      "Start: Bowlus2\n",
      "Done\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "pjDirectory = []\n",
    "pjName = []\n",
    "# read the 'DraftData' folder info, extract project name\n",
    "for root, dirs, files in os.walk(\".\\\\DraftData\", topdown=False):\n",
    "    for name in dirs:\n",
    "        pjDirectory.append(os.path.join(root, name))\n",
    "        pjName.append(name)\n",
    "        \n",
    "if len(pjName) > 0:\n",
    "    \n",
    "    finishedPj = open('.\\\\cvsResults\\\\finished.txt','r+')\n",
    "    lines = finishedPj.readlines()\n",
    "    print(lines)\n",
    "    existPjDir = []\n",
    "    existPjName = []\n",
    "    for line in lines:\n",
    "        \n",
    "        existPjName.append(line.strip())\n",
    "        existPjDir.append(os.path.join('.\\\\DraftData', line.strip()))\n",
    "\n",
    "    for k in range(len(existPjName)):\n",
    "        if existPjName[k] in pjName:\n",
    "            pjDirectory.remove(existPjDir[k])\n",
    "            pjName.remove(existPjName[k])\n",
    "    \n",
    "    if len(pjName) > 0:\n",
    "        for k in range(len(pjName)):\n",
    "            finishedPj.write(pjName[k]+'\\n')\n",
    "\n",
    "        print(\"Working on: \") \n",
    "        print(*pjName, sep = \", \")\n",
    "        # generate the cvs from p2m\n",
    "        cvsGen(pjDirectory, pjName)\n",
    "        # generate the mat from cvs\n",
    "        matGen(pjName)\n",
    "        print(\"Finished\")\n",
    "\n",
    "    else:\n",
    "        print(\"No new project\")\n",
    "        \n",
    "    finishedPj.close()\n",
    "    \n",
    "else:\n",
    "    print(\"No project in \\DraftData folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def txlocGen(projectName):\n",
    "    \n",
    "    matPath = ['.\\\\matResults\\\\' + name for name in projectName]\n",
    "    cvsPath = ['.\\\\cvsResults\\\\' + name for name in projectName]\n",
    "    \n",
    "    for i in range(len(projectName)):\n",
    "        \n",
    "        txcvsPath = cvsPath[i]+'\\\\tx_pos.csv'\n",
    "        # open cvs file\n",
    "        csv_data = pd.read_csv(txcvsPath)\n",
    "        ntx = 10 # setting is 10 tx\n",
    "        nparr = np.zeros([ntx,3])\n",
    "        \n",
    "        for k in range(ntx):\n",
    "            # coordinate = ['x', 'y', 'z']\n",
    "            nparr[k,0] = csv_data.loc[k, 'x']\n",
    "            nparr[k,1] = np.abs(csv_data.loc[k, 'y'])\n",
    "            nparr[k,2] = csv_data.loc[k, 'z']\n",
    "\n",
    "        nparr_doule = nparr.astype(np.float64)\n",
    "        # store mat\n",
    "        sio.savemat(matPath[i]+'\\\\'+projectName[i]+'_txloc.mat', {'txloc': nparr_doule})\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gen tx.mat\n",
    "pjDirectory = []\n",
    "pjName = []\n",
    "# read the 'DraftData' folder info, extract project name\n",
    "for root, dirs, files in os.walk(\".\\\\cvsResults\", topdown=False):\n",
    "    for name in dirs:\n",
    "        pjDirectory.append(os.path.join(root, name))\n",
    "        pjName.append(name)     \n",
    "txlocGen(pjName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Adrian', 'Bowlus', 'Brevort', 'Capistrano']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pjName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.\\\\cvsResults\\\\Adrian',\n",
       " '.\\\\cvsResults\\\\Bowlus',\n",
       " '.\\\\cvsResults\\\\Brevort',\n",
       " '.\\\\cvsResults\\\\Capistrano']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pjDirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-19.8"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvsPath = ['.\\\\cvsResults\\\\' + name for name in pjName]\n",
    "txcvsPath = cvsPath[0]+'\\\\tx_pos.csv'\n",
    "# open cvs file\n",
    "csv_data = pd.read_csv(txcvsPath)\n",
    "ntx = 10 # setting is 10 tx\n",
    "csv_data.loc[0, 'y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
